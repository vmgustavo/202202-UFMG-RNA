{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, silhouette_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.datasets import (\n",
    "    alldts, get_blobs, get_linear,\n",
    "    get_breast_cancer_wisconsin, get_breast_cancer_coimbra, get_german_credit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = get_breast_cancer_wisconsin()\n",
    "# data, target = get_blobs(n_obs=512)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.values, target.values, stratify=target, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(int(2**13), ), activation=\"tanh\", solver=\"adam\",\n",
    "    alpha=0, beta_1=0.9, beta_2=0.999,\n",
    "    max_iter=100,\n",
    "    verbose=True, shuffle=False,\n",
    "    early_stopping=False, validation_fraction=0.1,\n",
    "    n_iter_no_change=256, tol=1e-6,\n",
    "    epsilon=1e-8, learning_rate=\"constant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred=model.predict(X_train), y_true=y_train), accuracy_score(y_pred=model.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_curve_)\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, \"both\", alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=model.predict(X_train), y_true=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=model.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute for all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list()\n",
    "\n",
    "for name, (data, target) in alldts().items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.values, target.values, stratify=target, test_size=.1)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(int(2**10), ), activation=\"tanh\", solver=\"adam\",\n",
    "        alpha=0, beta_1=0.9, beta_2=0.999,\n",
    "        max_iter=1024,\n",
    "        verbose=False, shuffle=False,\n",
    "        early_stopping=False, validation_fraction=0.1,\n",
    "        n_iter_no_change=128, tol=1e-6,\n",
    "        epsilon=1e-8, learning_rate=\"constant\",\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    res.append((\n",
    "        name,\n",
    "        accuracy_score(y_pred=model.predict(X_train), y_true=y_train),\n",
    "        accuracy_score(y_pred=model.predict(X_test), y_true=y_test),\n",
    "        model.best_loss_\n",
    "    ))\n",
    "    print(res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in res:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "('synth_linear', 0.9788388497015735, 0.9707317073170731, 0.052382419507525285)\n",
    "('synth_blobs', 0.8562126966901791, 0.8634146341463415, 0.3211682111107963)\n",
    "('synth_moons', 0.9739555073250136, 0.975609756097561, 0.07893427880505421)\n",
    "('cred_aus', 1.0, 0.8115942028985508, 0.003973575106792552)\n",
    "('cred_ger', 1.0, 0.73, 0.00016377633931161258)\n",
    "('banknote', 1.0, 1.0, 9.819143678097311e-05)\n",
    "('breast_coimbra', 1.0, 0.5833333333333334, 0.0016671655433862797)\n",
    "('breast_wiscons', 0.998371335504886, 0.9855072463768116, 0.010349796410566922)\n",
    "('haberman_surv', 0.7927272727272727, 0.7741935483870968, 0.4558088231894344)\n",
    "('sonar', 1.0, 0.9047619047619048, 0.00025074506213388937)\n",
    "('heart', 1.0, 0.7777777777777778, 0.0024350693271338307)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list()\n",
    "\n",
    "for name, (data, target) in alldts().items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.values, target.values, stratify=target, test_size=.1)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(int(2**10), ), activation=\"tanh\", solver=\"lbfgs\",\n",
    "        alpha=0, beta_1=0.9, beta_2=0.999,\n",
    "        max_iter=1024,\n",
    "        verbose=False, shuffle=False,\n",
    "        early_stopping=False, validation_fraction=0.1,\n",
    "        n_iter_no_change=128, tol=1e-6,\n",
    "        epsilon=1e-8, learning_rate=\"constant\",\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    res.append((\n",
    "        name,\n",
    "        accuracy_score(y_pred=model.predict(X_train), y_true=y_train),\n",
    "        accuracy_score(y_pred=model.predict(X_test), y_true=y_test)\n",
    "    ))\n",
    "    print(res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in res:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "('synth_linear', 1.0, 0.9317073170731708)\n",
    "('synth_blobs', 0.8811720021703744, 0.8536585365853658)\n",
    "('synth_moons', 0.9858925664677157, 0.9560975609756097)\n",
    "('cred_aus', 1.0, 0.7681159420289855)\n",
    "('cred_ger', 1.0, 0.76)\n",
    "('banknote', 1.0, 1.0)\n",
    "('breast_coimbra', 1.0, 0.8333333333333334)\n",
    "('breast_wiscons', 1.0, 0.9420289855072463)\n",
    "('haberman_surv', 0.9818181818181818, 0.6451612903225806)\n",
    "('sonar', 1.0, 0.8571428571428571)\n",
    "('heart', 1.0, 0.7407407407407407)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute for specific datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coimbra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    res = list()\n",
    "\n",
    "    for _ in tqdm(range(30)):\n",
    "        data, target = get_breast_cancer_coimbra()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.values, target.values, stratify=target, test_size=.3)\n",
    "\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(int(2**10), ), activation=\"tanh\", solver=\"adam\",\n",
    "            alpha=0, beta_1=0.9, beta_2=0.999,\n",
    "            max_iter=2048,\n",
    "            verbose=False, shuffle=False,\n",
    "            early_stopping=False, validation_fraction=0.1,\n",
    "            n_iter_no_change=128, tol=1e-6,\n",
    "            epsilon=1e-8, learning_rate=\"constant\",\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        res.append((\n",
    "            accuracy_score(y_pred=model.predict(X_train), y_true=y_train),\n",
    "            accuracy_score(y_pred=model.predict(X_test), y_true=y_test),\n",
    "            model.best_loss_\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res)[1].plot.hist(bins=np.linspace(0, 1, 21), figsize=(5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    res = list()\n",
    "\n",
    "    for _ in tqdm(range(30)):\n",
    "        data, target = get_german_credit()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.values, target.values, stratify=target, test_size=.3)\n",
    "\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(int(2**10), ), activation=\"tanh\", solver=\"adam\",\n",
    "            alpha=0, beta_1=0.9, beta_2=0.999,\n",
    "            max_iter=2048,\n",
    "            verbose=False, shuffle=False,\n",
    "            early_stopping=False, validation_fraction=0.1,\n",
    "            n_iter_no_change=128, tol=1e-6,\n",
    "            epsilon=1e-8, learning_rate=\"constant\",\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        res.append((\n",
    "            accuracy_score(y_pred=model.predict(X_train), y_true=y_train),\n",
    "            accuracy_score(y_pred=model.predict(X_test), y_true=y_test),\n",
    "            model.best_loss_\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res)[1].plot.hist(bins=np.linspace(0, 1, 21), figsize=(5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    silhouette_samples, silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    ")\n",
    "def sil_neg_samples_score(X, labels):\n",
    "    res = silhouette_samples(X, labels)\n",
    "\n",
    "    counts = Counter(res > 0)\n",
    "    return counts[False] / (counts[False] + counts[True])\n",
    "    \n",
    "def cluster_evaluate(X, labels):\n",
    "    metrics = [\n",
    "        silhouette_score,\n",
    "        sil_neg_samples_score,\n",
    "        calinski_harabasz_score,\n",
    "        davies_bouldin_score,\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        metric.__name__: metric(X=X, labels=labels)\n",
    "        for metric in metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 10\n",
    "alphas = [0] + list(np.logspace(-1, 1/2, num=20))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    res = list()\n",
    "\n",
    "    for _, alpha in tqdm(list(product(range(repeat), alphas))):\n",
    "        data, target = get_german_credit()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.values, target.values, stratify=target, test_size=.3)\n",
    "\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 32, 16, 8, 4, 2), activation=\"tanh\", solver=\"adam\",\n",
    "            alpha=alpha, beta_1=0.9, beta_2=0.999,\n",
    "            max_iter=1024,\n",
    "            verbose=False, shuffle=False,\n",
    "            early_stopping=False, validation_fraction=0.1,\n",
    "            n_iter_no_change=512, tol=1e-6,\n",
    "            epsilon=1e-8, learning_rate=\"constant\",\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        break\n",
    "\n",
    "        res.append(dict({\n",
    "            \"alpha\": alpha,\n",
    "            \"acc_train\": accuracy_score(y_pred=model.predict(X_train), y_true=y_train),\n",
    "            \"acc_test\": accuracy_score(y_pred=model.predict(X_test), y_true=y_test),\n",
    "            \"best_loss\": model.best_loss_,\n",
    "            \"iterations\": model.n_iter_\n",
    "        }, **cluster_evaluate(X=np.tanh(X_train @ model.coefs_[0]), labels=y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(a, b):\n",
    "    return np.tanh(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = reduce(feed_forward, [X_train] + model.coefs_[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_evaluate(X=projection, labels=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.json_normalize(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_grouped = df_res.groupby(\"alpha\", as_index=False).mean()\n",
    "df_res_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_grouped.corrwith(df_res_grouped[\"acc_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2))\n",
    "ax = plt.gca()\n",
    "\n",
    "x = df_res[\"alpha\"]\n",
    "poly_train = np.poly1d(np.polyfit(df_res[\"alpha\"], df_res[\"acc_train\"], 1))\n",
    "poly_test = np.poly1d(np.polyfit(df_res[\"alpha\"], df_res[\"acc_test\"], 1))\n",
    "\n",
    "plt.plot(x, poly_train(x), label=\"train\")\n",
    "plt.plot(x, poly_test(x), label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "(\n",
    "    df_res\n",
    "    [[\"alpha\", \"acc_train\"]]\n",
    "    .plot.scatter(\n",
    "        x=[\"alpha\"],\n",
    "        y=[\"acc_train\"],\n",
    "        c=\"black\", edgecolors=\"black\", alpha=.5,\n",
    "        ax=ax, label=\"acc_train\",\n",
    "    )\n",
    ")\n",
    "\n",
    "(\n",
    "    df_res\n",
    "    [[\"alpha\", \"acc_test\"]]\n",
    "    .plot.scatter(\n",
    "        x=[\"alpha\"],\n",
    "        y=[\"acc_test\"],\n",
    "        c=\"white\", edgecolors=\"black\", alpha=.5,\n",
    "        ax=ax, label=\"acc_test\",\n",
    "    )\n",
    ")\n",
    "\n",
    "axt = ax.twinx()\n",
    "\n",
    "(\n",
    "    df_res\n",
    "    [[\"alpha\", \"silhouette_score\"]]\n",
    "    .plot.scatter(\n",
    "        x=\"alpha\",\n",
    "        y=\"silhouette_score\",\n",
    "        c=\"red\", alpha=.2,\n",
    "        ax=axt, label=\"silhouette_score\"\n",
    "    )\n",
    ")\n",
    "\n",
    "axt2 = ax.twinx()\n",
    "\n",
    "(\n",
    "    df_res\n",
    "    [[\"alpha\", \"silhouette_neg_samples\"]]\n",
    "    .plot.scatter(\n",
    "        x=\"alpha\",\n",
    "        y=\"silhouette_neg_samples\",\n",
    "        c=\"blue\", alpha=.2,\n",
    "        ax=axt2, label=\"silhouette_neg_samples\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ax.legend(bbox_to_anchor=(0, 1), loc=\"lower left\")\n",
    "axt.legend(bbox_to_anchor=(1, 1), loc=\"lower right\")\n",
    "axt2.legend(bbox_to_anchor=(1, 1.1), loc=\"lower right\")\n",
    "axt2.spines.right.set_position((\"axes\", 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5aaa17ceaad73b17e34098533828f17edc35a2441ebc374a71d3291ab1f65c24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
