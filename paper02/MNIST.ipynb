{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with SciKit-Learn and skorch\n",
    "\n",
    "This notebooks shows how to define and train a simple Neural-Network with PyTorch and use it via skorch with SciKit-Learn.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\">View source on GitHub</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Using SciKit-Learns ```fetch_openml``` to load MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
    "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(), X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: data is not normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([3, 2, 8, ..., 1, 0, 0]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 784), (52500,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a selection of training images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        plt.subplot(151 + i)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network with PyTorch\n",
    "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maia/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dim = X.shape[1]\n",
    "hidden_dim = int(mnist_dim/8)\n",
    "output_dim = len(np.unique(mnist.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 98, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dim, hidden_dim, output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Neural network in PyTorch's framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=mnist_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skorch allows to use PyTorch's networks in the SciKit-Learn setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import get_blobs\n",
    "\n",
    "data, target = get_blobs(n_obs=128)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (76x2 and 784x98)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m net\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/classifier.py:141\u001b[0m, in \u001b[0;36mNeuralNetClassifier.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[39mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m# this is actually a pylint bug:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(NeuralNetClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1230\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[0;32m-> 1230\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1189\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[1;32m   1188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1101\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m   1099\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_epoch_begin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single_epoch(iterator_train, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1102\u001b[0m                           step_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(iterator_valid, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1105\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m   1107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1137\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[0;34m(self, iterator, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_batch_begin\u001b[39m\u001b[39m\"\u001b[39m, batch\u001b[39m=\u001b[39mbatch, training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m-> 1137\u001b[0m     step \u001b[39m=\u001b[39m step_fn(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mrecord_batch(prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, step[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[1;32m   1139\u001b[0m     batch_size \u001b[39m=\u001b[39m (get_len(batch[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[1;32m   1140\u001b[0m                   \u001b[39melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1016\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[1;32m   1010\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1011\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1012\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m     \u001b[39mreturn\u001b[39;00m step[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1016\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_optimizer(step_fn)\n\u001b[1;32m   1017\u001b[0m \u001b[39mreturn\u001b[39;00m step_accumulator\u001b[39m.\u001b[39mget_step()\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:972\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[0;34m(self, step_fn)\u001b[0m\n\u001b[1;32m    970\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(step_fn)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/optim/sgd.py:113\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 113\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    116\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1006\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_fn\u001b[39m():\n\u001b[1;32m   1005\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_optimizer()\n\u001b[0;32m-> 1006\u001b[0m     step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step_single(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1007\u001b[0m     step_accumulator\u001b[39m.\u001b[39mstore_step(step)\n\u001b[1;32m   1009\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[1;32m   1010\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1011\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[1;32m   1012\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[1;32m   1013\u001b[0m     )\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:905\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[0;34m(self, batch, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_training(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    904\u001b[0m Xi, yi \u001b[39m=\u001b[39m unpack_data(batch)\n\u001b[0;32m--> 905\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(Xi, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    906\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_loss(y_pred, yi, X\u001b[39m=\u001b[39mXi, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    907\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/skorch/net.py:1427\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     x_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[1;32m   1426\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx_dict)\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule_(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [16], line 16\u001b[0m, in \u001b[0;36mClassifierModule.forward\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 16\u001b[0m     X \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden(X))\n\u001b[1;32m     17\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(X)\n\u001b[1;32m     18\u001b[0m     X \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(X), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/UFMG/202202-UFMG-RNA/.venv/lib/python3.9/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   1847\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1848\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (76x2 and 784x98)"
     ]
    }
   ],
   "source": [
    "net.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "5aaa17ceaad73b17e34098533828f17edc35a2441ebc374a71d3291ab1f65c24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
